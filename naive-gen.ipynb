{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "      )\n",
       "      (decoder): Linear(in_features=1024, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertForMaskedLM.from_pretrained('bert-large-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "CLS = '[CLS]'\n",
    "SEP = '[SEP]'\n",
    "MASK = '[MASK]'\n",
    "\n",
    "mask_id = tokenizer.convert_tokens_to_ids([MASK])[0]\n",
    "sep_id = tokenizer.convert_tokens_to_ids([MASK])[0]\n",
    "cls_id = tokenizer.convert_tokens_to_ids([MASK])[0]\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Generation modes as functions '''\n",
    "\n",
    "def generate(out, gen_idx, temperature=None, top_k=0, sample=False):\n",
    "    \"\"\" Generate a word from from out[gen_idx]\n",
    "    \n",
    "    args:\n",
    "        - out (torch.Tensor): tensor of logits of size batch_size x seq_len x vocab_size\n",
    "        - gen_idx (int): location for which to generate for\n",
    "        - top_k (int): if >0, only sample from the top k most probable words\n",
    "        - sample (Bool): if True, sample from full distribution. Overridden by top_k \n",
    "    \"\"\"\n",
    "    logits = out[0, gen_idx]\n",
    "    if temperature is not None:\n",
    "        logits = logits / temperature\n",
    "    if top_k > 0:\n",
    "        kth_vals, kth_idx = logits.topk(top_k)\n",
    "        dist = torch.distributions.categorical.Categorical(logits=kth_vals)\n",
    "        idx = kth_idx[dist.sample().item()].item()\n",
    "    elif sample:\n",
    "        dist = torch.distributions.categorical.Categorical(logits=logits)\n",
    "        idx = dist.sample().item()\n",
    "    else:\n",
    "        idx = torch.max(logits,0)[1].item()\n",
    "    return idx\n",
    "\n",
    "def get_init_text(seed_text, max_len, rand_init=False):\n",
    "    \"\"\" Get initial sentence by padding seed_text with either masks or random words to max_len \"\"\"\n",
    "    init_text = seed_text + [MASK] * max_len + [SEP]\n",
    "    if rand_init:\n",
    "        for ii in range(max_len):\n",
    "            init_idx[seed_len+ii] = numpy.random.randint(0, len(tokenizer.vocab))\n",
    "    \n",
    "    return tokenizer.convert_tokens_to_ids(init_text)\n",
    "\n",
    "def parallel_sequential_generation(seed_text, max_len=15, top_k=0, temperature=None, max_iter=300, burnin=200, print_every=10):\n",
    "    \"\"\" Generate for one random position at a timestep\n",
    "    \n",
    "    args:\n",
    "        - burnin: during burn-in period, sample from full distribution; afterwards take argmax\n",
    "    \"\"\"\n",
    "    seed_len = len(seed_text)\n",
    "    init_idx = get_init_text(seed_text, max_len)\n",
    "    \n",
    "    for ii in range(max_iter):\n",
    "        kk = numpy.random.randint(0, max_len)\n",
    "        init_idx[seed_len+kk] = mask_id\n",
    "        out = model(torch.tensor([init_idx]))\n",
    "        init_idx[seed_len+kk] = generate(out, gen_idx=seed_len+kk, top_k=top_k, sample=(ii < burnin))\n",
    "\n",
    "        if numpy.mod(ii+1, print_every) == 0:\n",
    "            for_print = tokenizer.convert_ids_to_tokens(init_idx)\n",
    "            for_print = for_print[:seed_len+kk+1] + ['(*)'] + for_print[seed_len+kk+1:]\n",
    "            print(\"iter\", ii+1, \" \".join(for_print))\n",
    "    return\n",
    "\n",
    "def parallel_generation(seed_text, max_len=15, top_k=0, temperature=None, max_iter=300, sample=True, print_every=10):\n",
    "    \"\"\" Generate for all positions at a time step \"\"\"\n",
    "    seed_len = len(seed_text)\n",
    "    init_idx = get_init_text(seed_text, max_len)\n",
    "    \n",
    "    for ii in range(max_iter):\n",
    "        out = model(torch.tensor([init_idx]))\n",
    "        for kk in range(max_len):\n",
    "            init_idx[seed_len+kk] = generate(out, gen_idx=seed_len+kk, top_k=top_k, sample=sample)\n",
    "            \n",
    "        if numpy.mod(ii, print_every) == 0:\n",
    "            print(\"iter\", ii+1, \" \".join(tokenizer.convert_ids_to_tokens(init_idx)))\n",
    "    return\n",
    "            \n",
    "def sequential_generation(seed_text, max_len=15, leed_out_len=15, top_k=0, temperature=None, sample=True):\n",
    "    \"\"\" Generate one word at a time, in L->R order \"\"\"\n",
    "    seed_len = len(seed_text)\n",
    "    init_idx = get_init_text(seed_text, max_len)\n",
    "\n",
    "    for ii in range(max_len):\n",
    "        inp = [init_idx[:seed_len+ii+leed_out_len]+[sep_id]]\n",
    "        out = model(torch.tensor(inp))\n",
    "        init_idx[seed_len+ii] = generate(out, gen_idx=seed_len+ii, top_k=top_k, sample=sample)\n",
    "\n",
    "    print(\" \".join(tokenizer.convert_ids_to_tokens(init_idx)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 [CLS] [MASK] son the chinese [MASK] [MASK] [MASK] [MASK] [MASK] them 6 children (*) cai [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [SEP]\n",
      "iter 20 [CLS] [MASK] married the heiress [MASK] [MASK] . [MASK] [MASK] had 6 children including [MASK] elisabeth (*) [MASK] , later empress [MASK] [SEP]\n",
      "iter 30 [CLS] [MASK] married an heiress (*) , elizabeth , [MASK] [MASK] had various children including [MASK] mary [MASK] , later empress [MASK] [SEP]\n",
      "iter 40 [CLS] [MASK] married an heiress , alice , too who had various children including [MASK] and elizabeth (*) , later queen [MASK] [SEP]\n",
      "iter 50 [CLS] james married an (*) heiress named alice , too who had three children including [MASK] and elizabeth , later queen [MASK] [SEP]\n",
      "iter 60 [CLS] james married (*) an heiress named anna , too who had three children , henry and margaret , future queen . [SEP]\n",
      "iter 70 [CLS] james married an heiress , katherine , of who were three children , henry and mary , later (*) queen . [SEP]\n",
      "iter 80 [CLS] james married the (*) heiress , anne , from whom came three children , henry and mary , later artists . [SEP]\n",
      "iter 90 [CLS] atkinson married the heiress , harriet , from whom came three children : henry and mary , later artists . (*) [SEP]\n",
      "iter 100 [CLS] atkinson married an heiress , hannah , from whom were two children , (*) henry and mary , later artists . [SEP]\n",
      "iter 110 [CLS] atkinson married an heiress named hannah , from whom were two children , henry and daniel , both (*) artists . [SEP]\n",
      "iter 120 [CLS] he married an heiress named hannah , (*) from whom were two children , ashe and daniel , both artists . [SEP]\n",
      "iter 130 [CLS] he married an (*) heiress named hannah , from whom were two children , mary and daniel , both artists . [SEP]\n",
      "iter 140 [CLS] he married an actress named hannah jenkins (*) from whom were two daughters , amanda and richard , both artists . [SEP]\n",
      "iter 150 [CLS] he married an heiress named catherine (*) jenkins of whom were two children , kate and richard , both ministers . [SEP]\n",
      "iter 160 [CLS] he married an heiress named catherine jenkins of gloucestershire his two (*) sons , thomas and richard were both ministers . [SEP]\n",
      "iter 170 [CLS] he married an heiress , catherine jenkins of gloucestershire his two sons , thomas and john were (*) both ministers . [SEP]\n",
      "iter 180 [CLS] he married an heiress (*) , matthew jenkins of whom his two sons , william and john were both principals . [SEP]\n",
      "iter 190 [CLS] he married an heiress , matthew jenkins of whom their (*) two sons , richard and thomas were both principals . [SEP]\n",
      "iter 200 [CLS] he married the heiress of patrick (*) jenkins of whom their two sons , thomas and john were both ministers . [SEP]\n",
      "iter 210 [CLS] he married the daughter of patrick jenkins of (*) whom their two sons , thomas and john were prominent members . [SEP]\n",
      "iter 220 [CLS] he married the daughter (*) of thomas jenkins of whom their two sons , thomas and john were prominent members . [SEP]\n",
      "iter 230 [CLS] he married the daughter of thomas jenkins of whom his two sons , thomas and john were (*) prominent members . [SEP]\n",
      "iter 240 [CLS] he married the daughter (*) of thomas jenkins of which his two sons , thomas and john were also members . [SEP]\n",
      "iter 250 [CLS] he married a daughter of thomas jenkins of which his two sons , thomas and john (*) were also members . [SEP]\n",
      "iter 260 [CLS] he married a daughter of thomas jenkins of which his two sons , william (*) and john were also members . [SEP]\n",
      "iter 270 [CLS] he married a daughter of thomas jenkins of which family two sons , william and john were also mps (*) . [SEP]\n",
      "iter 280 [CLS] he married a daughter of (*) john jenkins of which family two sons , william and john were also mps . [SEP]\n",
      "iter 290 [CLS] he married a daughter of john jenkins of (*) which their two sons , william and john were also members . [SEP]\n",
      "iter 300 [CLS] he married a daughter of thomas , of which their two sons , thomas (*) and john were also members . [SEP]\n"
     ]
    }
   ],
   "source": [
    "n_sample = 1\n",
    "max_len = 20\n",
    "top_k = 0\n",
    "temperature=5.\n",
    "\n",
    "leed_out_len = 5 # max_len\n",
    "burnin = 200\n",
    "sample = True\n",
    "max_iter = 300\n",
    "\n",
    "seed_text = \"[CLS]\".split()\n",
    "init_idx = get_init_text(seed_text, max_len)\n",
    "for _ in range(n_sample):\n",
    "    parallel_sequential_generation(seed_text, max_len=max_len, top_k=top_k, temperature=temperature, burnin=burnin, max_iter=max_iter)\n",
    "    #sequential_generation(seed_text, max_len=max_len, top_k=top_k, temperature=temperature, leed_out_len=leed_out_len, sample=sample)\n",
    "    #parallel_generation(seed_text, max_len=max_len, top_k=top_k, temperature=temperature, sample=sample, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK] york is the greatest city in the world . [SEP] => new ||| rank of new 1\n",
      "[CLS] new [MASK] is the greatest city in the world . [SEP] => york ||| rank of york 1\n",
      "[CLS] new york [MASK] the greatest city in the world . [SEP] => is ||| rank of is 1\n",
      "[CLS] new york is [MASK] greatest city in the world . [SEP] => the ||| rank of the 1\n",
      "[CLS] new york is the [MASK] city in the world . [SEP] => largest ||| rank of greatest 15\n",
      "[CLS] new york is the greatest [MASK] in the world . [SEP] => city ||| rank of city 1\n",
      "[CLS] new york is the greatest city [MASK] the world . [SEP] => in ||| rank of in 1\n",
      "[CLS] new york is the greatest city in [MASK] world . [SEP] => the ||| rank of the 1\n",
      "[CLS] new york is the greatest city in the [MASK] . [SEP] => world ||| rank of world 1\n",
      "[CLS] new york is the greatest city in the world [MASK] [SEP] => . ||| rank of . 1\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "original_sent = [CLS] + 'new york is the greatest city in the world . '.lower().split() + [SEP]\n",
    "\n",
    "for ii_ in range(len(original_sent)-2):\n",
    "    ii = ii_ + 1\n",
    "    new_sent = copy.copy(original_sent)\n",
    "    new_sent[ii] = '[MASK]'\n",
    "#     new_sent[ii] = tokenizer.convert_ids_to_tokens([numpy.random.randint(0, len(tokenizer.vocab))])[0]\n",
    "    out = model(torch.tensor([tokenizer.convert_tokens_to_ids(new_sent)]))\n",
    "    pred = tokenizer.convert_ids_to_tokens([out[0][ii].max(0)[1].item()])[0]\n",
    "    probs = out[0][ii].data.numpy()\n",
    "    rank = len(tokenizer.vocab) - numpy.argsort(numpy.argsort(probs))[tokenizer.convert_tokens_to_ids([original_sent[ii]])[0]]\n",
    "    print(\" \".join(new_sent), \"=>\", pred, '|||', 'rank of', original_sent[ii], rank)\n",
    "#     if pred == 'the':\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] & von berg ##h . & von berg ##h . & von berg ##h . & von berg ##h .\n",
      "[CLS] and a dozen hundred thousand people . and ten thousand more , for four thousand thousand thousand more cities .\n",
      "[CLS] von der mann . von den man . von der mann . von die mann . von den man .\n",
      "[CLS] and how low the price was . and how many girls had died for a couple of stupid lies .\n",
      "[CLS] ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ; ;\n",
      "[CLS] and the thing had been thrown along the ground in its own small , white , or ##c wake .\n",
      "[CLS] and three dozen dozen of the great many thousand of the four hundred thousand of the many thousand thousand .\n",
      "[CLS] 8 . 40 ##m . 4 . 39 ##m . 5 . 02 ##m . 7 . 74 ##m .\n",
      "[CLS] ( in ( 3 . 13 . 11 . 17 . 17 ) ; # 1 ; 7 ) .\n",
      "[CLS] ( in : int . social sciences and social issues . roman ##a : academia del soc ##orro ) .\n"
     ]
    }
   ],
   "source": [
    "''' sequential generation: this one kinda works '''\n",
    "\n",
    "sep_id = tokenizer.convert_tokens_to_ids([SEP])\n",
    "sample = True\n",
    "max_len = 20\n",
    "leed_out_len = 5 #max_len\n",
    "random_future = False\n",
    "top_k = 100 # set it to 0 if you don't want top_k\n",
    "n_samples = 10\n",
    "\n",
    "seed_text = [CLS] # + \"this is\".split()\n",
    "seed_len = len(seed_text)\n",
    "\n",
    "for si in range(n_samples):\n",
    "    init_text = seed_text + ['[MASK]'] * max_len\n",
    "    init_idx = tokenizer.convert_tokens_to_ids(init_text)\n",
    "    if random_future:\n",
    "        for ii in range(max_len):\n",
    "            init_idx[seed_len+ii] = numpy.random.randint(0, len(tokenizer.vocab))\n",
    "\n",
    "    for ii in range(max_len):\n",
    "        out = model(torch.tensor([init_idx[:seed_len+ii+leed_out_len]+sep_id]))\n",
    "        if top_k > 0:\n",
    "            logits = out[0,seed_len+ii]\n",
    "            kth_vals, kth_idx = logits.topk(top_k)\n",
    "            dist = torch.distributions.categorical.Categorical(logits=kth_vals)\n",
    "            init_idx[seed_len+ii] = kth_idx[dist.sample().item()].item()\n",
    "        else:\n",
    "            if sample:\n",
    "                dist = torch.distributions.categorical.Categorical(logits=out[0,seed_len+ii])\n",
    "                init_idx[seed_len+ii] = dist.sample().item()\n",
    "            else:\n",
    "                init_idx[seed_len+ii] = torch.max(out[0, seed_len+ii],0)[1].item()\n",
    "\n",
    "#     print(init_idx)\n",
    "    print(\" \".join(tokenizer.convert_ids_to_tokens(init_idx)))\n",
    "# print(\" \".join(tokenizer.convert_ids_to_tokens(init_idx)).replace(\" ##\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 [CLS] philippine \" ##hara ##id on mir by character sons five god with the , ; for a fatal ##in ; [SEP]\n",
      "iter 11 [CLS] 2 m be ##h on ##r by the to . god with . aid ; for present definite h . [SEP]\n",
      "iter 21 [CLS] 2 ##m be ##h on ##r by the to . god with . aid ; for present definite h . [SEP]\n",
      "iter 31 [CLS] 2 ##m be ##h on ##s by the to . god with . aid ; for present definite h . [SEP]\n",
      "iter 41 [CLS] 2 ##m be ##h on ze by the to . god with . aid ; for which definite h . [SEP]\n",
      "iter 51 [CLS] 2 ##m be ##h on - by the to . god with . aid ; p or an h . [SEP]\n",
      "iter 61 [CLS] 2 ##m be ##h on made by the to . god with . help the p or an h . [SEP]\n",
      "iter 71 [CLS] 2 ##b be ##h on made by the to . god with . help the p or an h . [SEP]\n",
      "iter 81 [CLS] 2 ##b be ##h on made by the to . god with . help the p or an h . [SEP]\n",
      "iter 91 [CLS] 2 ##b be ##h is made by the to . god with . help the p or an h . [SEP]\n"
     ]
    }
   ],
   "source": [
    "''' parallel generation: this one doesn't work '''\n",
    "\n",
    "sample = True\n",
    "max_iter = 100\n",
    "viz_int = 10\n",
    "max_len = 20\n",
    "top_k = 0\n",
    "\n",
    "seed_text = '[CLS]'.split()\n",
    "seed_len = len(seed_text)\n",
    "\n",
    "init_text = seed_text + ['[MASK]'] * max_len + ['[SEP]']\n",
    "init_idx = tokenizer.convert_tokens_to_ids(init_text)\n",
    "# for ii in range(max_len):\n",
    "#     init_idx[seed_len+ii] = numpy.random.randint(0, len(tokenizer.vocab))\n",
    "\n",
    "for ii in range(max_iter):\n",
    "    out = model(torch.tensor([init_idx]))\n",
    "    for kk in range(max_len):\n",
    "        if top_k > 0:\n",
    "            logits = out[0,seed_len+kk]\n",
    "            kth_vals, kth_idx = logits.topk(top_k)\n",
    "            dist = torch.distributions.categorical.Categorical(logits=kth_vals)\n",
    "            init_idx[seed_len+kk] = kth_idx[dist.sample().item()].item()\n",
    "        else:\n",
    "            if sample:\n",
    "                dist = torch.distributions.categorical.Categorical(logits=out[0,seed_len+kk])\n",
    "                init_idx[seed_len+kk] = dist.sample().item()\n",
    "            else:\n",
    "                init_idx[seed_len+kk] = torch.max(out[0, seed_len+kk],0)[1].item()\n",
    "    if numpy.mod(ii, viz_int) == 0:\n",
    "        print(\"iter\", ii+1, \" \".join(tokenizer.convert_ids_to_tokens(init_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 [CLS] un (*) ##i [MASK] [MASK] [MASK] ; [MASK] . [MASK] ##i [MASK] : ; [MASK] [MASK] [SEP]\n",
      "iter 20 [CLS] xx ##ix [MASK] ; [MASK] . [MASK] . (*) [MASK] . [MASK] 2 ; b [MASK] [SEP]\n",
      "iter 30 [CLS] vi (*) . [MASK] ; [MASK] . [MASK] . 17 . ยง 2 : ii . [SEP]\n",
      "iter 40 [CLS] iii . 11 ; norway . iii . 17 . ยง 87 (*) . 1 . [SEP]\n",
      "iter 50 [CLS] iii . (*) sweden . norway ยง 11 . 17 & ยง 87 . 12 . [SEP]\n",
      "iter 60 [CLS] iii . denmark (*) & norway ยง 11 . 17 . ยง 87 . 20 . [SEP]\n",
      "iter 70 [CLS] iii . denmark & norway ยง 87 . 17 ; ยง 87 . (*) 20 ; [SEP]\n",
      "iter 80 [CLS] 4 . denmark & norway ยง 87 (*) . 17 ; ยง 87 . 20 ; [SEP]\n",
      "iter 90 [CLS] 4 . denmark & sweden ยง (*) 85 . 11 ; ยง 87 . 20 ; [SEP]\n",
      "iter 100 [CLS] 4 - denmark & norway (*) ยง 86 . 6 ; ยง 86 . 2 ; [SEP]\n",
      "iter 110 [CLS] cf . denmark - (*) norway ยง 86 . 5 ; ยง 86 . 7 ; [SEP]\n",
      "iter 120 [CLS] cf . denmark - schleswig (*) ยง 1886 . 5 , ยง 86 . 1 ; [SEP]\n",
      "iter 130 [CLS] cf . denmark v schleswig ยง 86 . (*) 5 , ยง 86 . 1 ; [SEP]\n",
      "iter 140 [CLS] cf . (*) denmark ser . ยง 86 . 2 , ยง 86 . 6 ; [SEP]\n",
      "iter 150 [CLS] cf . denmark ser . ยง 86 . 0 , ยง 86 . 2 ; (*) [SEP]\n",
      "iter 160 [CLS] em . denmark 56 (*) . ยง 86 . 0 ; ยง 86 . 45 ; [SEP]\n",
      "iter 170 [CLS] 1 (*) . denmark 56 . ยง 86 . 42 ; ยง 86 . 45 ; [SEP]\n",
      "iter 180 [CLS] 5 . ch 56 . ยง 86 . 42 , ยง 86 (*) . 45 . [SEP]\n",
      "iter 190 [CLS] 5 . ch ##s . ยง 86 . 35 , ยง (*) 86 . 45 . [SEP]\n",
      "iter 200 [CLS] 5 . pre ##s . ยง 86 . 35 and ยง 86 . 45 . (*) [SEP]\n",
      "iter 210 [CLS] 5 . con ##s . ยง 86 . 44 . (*) ยง 86 . 45 . [SEP]\n",
      "iter 220 [CLS] 5 . con ##st . ยง (*) 86 . 44 . ยง 86 . 45 . [SEP]\n",
      "iter 230 [CLS] 5 . di ##st . ยง (*) 86 . 44 , ยง 86 . 45 . [SEP]\n",
      "iter 240 [CLS] 5 . di ##st . ยง 86 . 44 , ยง (*) 86 . 45 . [SEP]\n",
      "iter 250 [CLS] stat . di ##st . ยง 86 . 44 (*) . ยง 86 . 45 . [SEP]\n",
      "iter 260 [CLS] stat . di ##st . ยง 86 . 44 . ยง 86 . 45 . (*) [SEP]\n",
      "iter 270 [CLS] stat . di ##st . ยง (*) 86 . 44 . ยง 86 . 45 . [SEP]\n",
      "iter 280 [CLS] stat . di ##st . ยง 86 (*) . 44 . ยง 86 . 45 . [SEP]\n",
      "iter 290 [CLS] stat . di ##st . ยง 86 . (*) 44 . ยง 86 . 45 . [SEP]\n",
      "iter 300 [CLS] stat (*) . di ##st . ยง 86 . 44 . ยง 86 . 45 . [SEP]\n"
     ]
    }
   ],
   "source": [
    "''' parallel-sequential generation: this one definitely works '''\n",
    "\n",
    "# sample = True\n",
    "burnin = 200\n",
    "max_iter = 300\n",
    "viz_int = 10\n",
    "max_len = 15\n",
    "top_k = 0\n",
    "\n",
    "seed_text = '[CLS]'.split()\n",
    "seed_len = len(seed_text)\n",
    "\n",
    "init_text = seed_text + ['[MASK]'] * (max_len) + ['[SEP]']\n",
    "init_idx = tokenizer.convert_tokens_to_ids(init_text)\n",
    "#for ii in range(max_len):\n",
    "#    init_idx[seed_len+ii] = numpy.random.randint(0, len(tokenizer.vocab))\n",
    "\n",
    "for ii in range(max_iter):\n",
    "    kk = numpy.random.randint(0, max_len)\n",
    "    init_idx[seed_len+kk] = tokenizer.convert_tokens_to_ids(['[MASK]'])[0]\n",
    "    out = model(torch.tensor([init_idx]))\n",
    "    if top_k > 0:\n",
    "        logits = out[0,seed_len+kk]\n",
    "        kth_vals, kth_idx = logits.topk(top_k)\n",
    "        dist = torch.distributions.categorical.Categorical(logits=kth_vals)\n",
    "        init_idx[seed_len+kk] = kth_idx[dist.sample().item()].item()\n",
    "    else:\n",
    "        if ii < burnin:\n",
    "            dist = torch.distributions.categorical.Categorical(logits=out[0,seed_len+kk])\n",
    "            init_idx[seed_len+kk] = dist.sample().item()\n",
    "        else:\n",
    "            init_idx[seed_len+kk] = torch.max(out[0, seed_len+kk],0)[1].item()\n",
    "        \n",
    "    if numpy.mod(ii+1, viz_int) == 0:\n",
    "        for_print = tokenizer.convert_ids_to_tokens(init_idx)\n",
    "        for_print = for_print[:seed_len+kk+1] + ['(*)'] + for_print[seed_len+kk+1:]\n",
    "        print(\"iter\", ii+1, \" \".join(for_print))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
